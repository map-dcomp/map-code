module protelis:com:bbn:map:resourcetracker

import com.bbn.protelis.networkresourcemanagement.ResourceSummary.getNullSummary
import com.bbn.protelis.networkresourcemanagement.ResourceSummary.merge
import com.bbn.protelis.networkresourcemanagement.ResourceSummary.convertToSummary

import com.bbn.protelis.networkresourcemanagement.ResourceReport.getShortEstimationWindow
import com.bbn.protelis.networkresourcemanagement.ResourceReport.getLongEstimationWindow

import com.bbn.protelis.networkresourcemanagement.LoadBalancerPlan.getNullLoadBalancerPlan
import com.bbn.protelis.networkresourcemanagement.RegionPlan.getNullRegionPlan

import com.bbn.map.NetworkAvailableServices.mergeNetworkAvailableServices
import com.bbn.map.NetworkAvailableServices.nullNetworkAvailableServices

import protelis:coord:sparsechoice
import protelis:coord:accumulation
import protelis:coord:spreading
import protelis:coord:meta
import protelis:lang:utils
import protelis:coord:nonselfstabilizing:accumulation
import protelis:state:nonselfstabilizing:time

import protelis:com:bbn:map:common

/**
 * Merge resource summaries.
 * 
 * @param a summary 1
 * @param b summary 2
 * @return the new merged summary
 */
def mergeSummaries(a,b) = merge(a,b)

/**
 * Summarize the ResourceReports and elect a DCOP leader. 
 * @param rgn (RegionIdentifier) the region to create the summary for
 * @param localSummary (ResourceSummary) the local summary
 * @param window (EstimationWindow) the estimation window to summarize over
 * @return (ResourceSummary) the summary for the region, will only be complete on the DCOP node
 */
def summarizeReports(rgn, window, localSummary, leader) {
    let d = hopDistanceTo(leader);
    C(d, mergeSummaries, localSummary, getNullSummary(rgn, window))
}

/**
 * Collect all of the ResourceReport objects for a region.
 * 
 * @return (Tuple<ResourceReport>) the reports for the region, will only be complete on the leader node
 * @param leader (boolean) true if this is node is the one to receive all of the reports
 */
def collectReports(leader) {
    let d = hopDistanceTo(leader);
    C(d, union, [self.getDevice().getResourceReport(getShortEstimationWindow())], [])
}

/**
 * Collect all of the ServiceReport objects for a region.
 * 
 * @return (Tuple<ServiceReport>) the reports for the region, will only be complete on the leader node
 * @param leader (boolean) true if this is the one to receive all of the reports
 */
def collectServiceReports(leader) {
    let d = hopDistanceTo(leader);
    C(d, union, [self.getDevice().getServiceReport()], [])
}

/**
 * Make sure that all nodes in the region have the RLG plan.
 * 
 * @param rgn (RegionIdentifier) the region to work with
 * @param isRlgLeader (boolean) true if self is the RLG leader
 */
def disseminateRlgPlan(rgn, isRlgLeader) {
    let rlgPlan = self.getDevice().getNetworkState().getLoadBalancerPlan();
    let rlgBroadcastedPlan = broadcastObjectToRegion(rgn, isRlgLeader, rlgPlan);
    
    //self.getDevice().apTraceMessage("Storing RLG plan of type: " + rlgBroadcastedPlan.getClass());   
    self.getDevice().getNetworkState().setLoadBalancerPlan(rlgBroadcastedPlan)
}

/**
 * Make sure that all nodes in the region have the DCOP plan.
 * 
 * @param rgn (RegionIdentifier) the region to work with
 * @param isDcopLeader (boolean) true if self is the DCOP leader
 */
def disseminateDcopPlan(rgn, isDcopLeader) {
    let dcopPlan = self.getDevice().getNetworkState().getRegionPlan();
    let dcopBroadcastedPlan = broadcastObjectToRegion(rgn, isDcopLeader, dcopPlan);
    
   // self.getDevice().apTraceMessage("Storing DCOP plan of type: " + dcopBroadcastedPlan.getClass());   
    self.getDevice().getNetworkState().setRegionPlan(dcopBroadcastedPlan)
}

/**
 * Broadcast an object to all nodes in the specified region.
 * 
 * @param rgn (RegionIdentifier) the region 
 * @param isLeader (boolean) the leader node
 * @param obj (Object) the object to broadcast
 */
def broadcastObjectToRegion(rgn, isLeader, obj) {
    self.getDevice().apTraceMessage("Sending object to all nodes: " + obj + " leader: " + isLeader);
    multiRegion(rgn,{ n -> rgn == n },
        { 
            hopBroadcast(isLeader, obj)
        },
        obj)
}

/**
 * Compute the ResourceSummary for the specified estimation window and store the summary.
 * The complete summary will only be present on the node running DCOP.
 * 
 * @param rgn (RegionIdentifier) the region to summarize across
 * @param window (EstimationWindow) the estimation window to compute the summary for
 * @param isDcopLeader (boolean) true if this node is the DCOP leader
 */
def computeResourceSummary(rgn, window, isDcopLeader) {
    //self.getDevice().apTraceMessage("Top of computeResourceSummary window: " + window);
    
    // summarize all reports for the region
    // Run the collection in the top-level so that we can get nbrs from other regions
    let localReport = self.getDevice().getResourceReport(window);
    //self.getDevice().apTraceMessage("Local report serverLoad: " + localReport.getComputeLoad());
    
    let localSummary = self.getDevice().convertToSummary(localReport);
    //self.getDevice().apTraceMessage("Local summary serverLoad: " + localSummary.getServerLoad());
    
    let s = multiRegion(rgn,{ n -> rgn == n }, {summarizeReports(rgn, window, localSummary, isDcopLeader)},[]);
    
    if(isDcopLeader) {
       // self.getDevice().apTraceMessage("Setting summary on " + self.getDevice().getName() + " to " + s.getServerLoad() + " is DCOP: " + isDcopLeader + " localLoad: " + localSummary.getServerLoad());
        self.getDevice().getNetworkState().setRegionSummary(s);
      //  self.getDevice().apTraceMessage("Bottom of computeResourceSummary window: " + window)
    } else {
        // nothing to do, need dummy statement though
        0
    }
}

/**
 * Share DCOP shared information to all regions and store it as needed.
 * 
 * @param isDcopLeader (boolean) if this node is running DCOP
 * @param rgn (RegionIdentifier) the region for this node
 */
def shareDcopInformation(rgn, isDcopLeader)  {
    let nbrRegions = findNeighborRegions(isDcopLeader);
    //self.getExecutionEnvironment().put("debug", nbrRegions);
    
    //self.getDevice().apTraceMessage("shareDcopInformation rgn: " + rgn + " leader? " + isDcopLeader + " nbrRegions: " + nbrRegions);
    
    let dcopShares = multiInstance(nbrRegions,
        { key -> 
            hopBroadcast(isDcopLeader && key==rgn, mux(isDcopLeader && key==rgn) {
                self.getDevice().getLocalDcopSharedInformation()
            }  else {
                // default to empty Tuple specifying that there is no information for the region
                // this value is filtered out in setAllDcopSharedInformation
                []
            })
        },
        []);
        
    if(isDcopLeader) {
       // self.getDevice().apTraceMessage("Storing DCOP shared information of type: " + dcopShares.getClass());           
        self.getDevice().setAllDcopSharedInformation(dcopShares)  
    } else {
        // nothing to do, need dummy statement though
        0 
    }
}

/**
 * Share RLG shared information to all regions and store it as needed.
 * 
 * @param isRlgLeader (boolean) if this node is running RLG
 * @param rgn (RegionIdentifier) the region for this node
 */
def shareRlgInformation(rgn, isRlgLeader)  {
    let nbrRegions = findNeighborRegions(isRlgLeader);
    
    let rlgShares = multiInstance(nbrRegions,
        { key ->             
            hopBroadcast(isRlgLeader && key==rgn, mux(isRlgLeader && key==rgn) {
                self.getDevice().getLocalRlgSharedInformation()
            } else { 
                // default to empty Tuple specifying that there is no information for the region
                // this value is filtered out in setAllRlgSharedInformation
                []
            })
        },
        []);
        
    if(isRlgLeader) {
     //   self.getDevice().apTraceMessage("Storing RLG shared information of type: " + rlgShares.getClass());                   
        self.getDevice().setAllRlgSharedInformation(rlgShares) 
    } else {
        // nothing to do, need a dummy statement though
        0
    }
}

def mergeNetworkAvailableServicesProtelis(a, b) {
  let ret = mergeNetworkAvailableServices(a, b);
  //self.getDevice().apTraceMessage("calling mergeNetworkAvailableServices with " + a + " and " + b + " -> " + ret);
  ret
}

def shareDnsInformation() {
    let device = self.getDevice();
    
    let globalLeader = if(device.isUseLeaderElection()) { electLeader() } else { device.isGlobalLeader() };
    device.setGlobalLeader(globalLeader);
    
    let cResult = C(hopDistanceTo(globalLeader), 
                    mergeNetworkAvailableServicesProtelis, 
                    self.getDevice().getLocalNetworkAvailableServices(), 
                    nullNetworkAvailableServices());
                    
   // device.apDebugMessage("global leader is: " + globalLeader + " cResult is: " + cResult);
                                        
    let allServices = hopBroadcast(globalLeader,cResult);
    
  //  device.apTraceMessage("Storing all services of type: " + allServices.getClass());                      
    device.setAllNetworkAvailableServices(allServices) 
} 

/**
 * Collect the service reports and store them on the DNS node.
 * 
 * @param leader true if this node is a leader for the service reports sharing
 * @param rgn (RegionIdentifier) the region for this node
 */
def shareServiceReports(rgn, leader) {
    let serviceReports = multiRegion(rgn,{ n -> rgn == n }, {collectServiceReports(leader)},[]);
    
    if(leader) {
        self.getDevice().setRegionServiceReports(serviceReports)
    } else {
        // nothing to do, need a dummy statement though
        0
    }    
}

// ---- main code

let neighbors = foldUnion([], nbr([self.getDevice().getNodeIdentifier()]));
self.getDevice().apDebugMessage("Neighbors protelis: " + neighbors + " java: " + self.getDevice().getNeighbors());

let rgn = self.getDevice().getRegionIdentifier();

let isDcopLeader = self.getDevice().isRunDCOP();
let isRlgLeader = self.getDevice().isRunRLG();
let isDnsHandler = self.getDevice().isHandleDnsChanges();

// compute the resource summary for all estimation windows
computeResourceSummary(rgn, getShortEstimationWindow(), isDcopLeader);
computeResourceSummary(rgn, getLongEstimationWindow(), isDcopLeader);


// collect all ResourceReport objects for this region, only complete on RLG node
let r = multiRegion(rgn,{ n -> rgn == n }, {collectReports(isRlgLeader)},[]);
if(isRlgLeader) {
    self.getDevice().apTraceMessage("Storing region resource reports of type: " + r.getClass());    
    self.getDevice().setRegionResourceReports(r)
}


self.getDevice().apTraceMessage("Calling shareServiceReports");
shareServiceReports(rgn, isDnsHandler);

self.getDevice().apTraceMessage("Calling disseminateRlgPlan");
disseminateRlgPlan(rgn, isRlgLeader);

self.getDevice().apTraceMessage("Calling disseminateDcopPlan");
disseminateDcopPlan(rgn, isDcopLeader);

self.getDevice().apTraceMessage("Calling shareDcopInformation");
shareDcopInformation(rgn, isDcopLeader);

self.getDevice().apTraceMessage("Calling shareRlgInformation");
shareRlgInformation(rgn, isRlgLeader);

self.getDevice().apTraceMessage("Calling shareDnsInformation");
shareDnsInformation();

// add some debugging output
self.getExecutionEnvironment().put("blue",self.getDevice().isRLGRunning());
self.getExecutionEnvironment().put("red",self.getDevice().isDCOPRunning());

self.getDevice().apTraceMessage("Protelis finished");

// Value to report for debugging purposes:
//[s.getRegion(), r.size() + " Reports", s.getServerCapacity()]
//[s.getRegion(), r.size() + " Reports", s.getServerLoad(), s.getNetworkLoad()]
[rgn, "Num reports: " + r.size()]

//let report = self.getDevice().getResourceReport(getShortEstimationWindow());
//let d = report.getClientDemand();
//let c = report.getServerCapacity();
//[d,c,s]
